
#### Further OpenAI - Matt Levine

A few quick points.

First, University of Kentucky law professor [Alan James Kluegel](https://law.uky.edu/people/alan-kluegel) emailed me to suggest a theory that maps the OpenAI conflict - between its nonprofit board that worried about AI safety, and its employees who love Altman and wanted him back - onto a straightforward valuation dispute:

> The board is made up of AI evangelists; the reason they openly worry about AI getting _too powerful_ is out of a belief in the potential for a godlike AI or at least out of concern that this soon-to-be-ubiquitous technology should be in its best possible shape before being distributed to the world. ...
>
> The employees, however, are familiar with all of the AI's limitations and problems and costs, and - being Silicon Valley veterans - are also familiar with the hype cycle at play here. …
>
> In other words, this is a story about the employees wanting to secure the bag while the unrealized potential of their product has captured everyone's attention and imagination, and Sam Altman's fundraising (and the Thrive Capital tender offer, in particular) was going to be their golden ticket - until the starry-eyed board killed their payday in a flurry of techno-optimistic excitement.

This is absolutely not at all what anyone was _saying_, and I suspect that it is not what anyone was _thinking_, but I like it as an objective explanation of what they were _doing_. It is not unheard-of for a startup to get a pretty high valuation, and for its employees to think "hey let's cash out while the money is there," while its board members are venture capitalists with diversified portfolios and liquidation preferences who are more willing to wait and gamble. Venture capitalist board members are _supposed_ to be able to take the long view and bet on changing the world, while employees are often more risk-averse and need cash to pay the mortgage.

OpenAI's board members are not venture capitalists, don't own equity at all, are not motivated by hopes of a trillion-dollar valuation, and were in fact adverse to its venture capitalist investors. And yet I think the model applies. They took a very long and grandiose view of the importance of their product and its ability to change the world, while the employees would like to see some cash now.

Second, we [talked last week](https://www.bloomberg.com/opinion/articles/2023-11-21/openai-is-a-strange-nonprofit) about the oddity of OpenAI as a nonprofit organization with a board that does not answer to shareholders. Tyler Cowen [pointed out](https://marginalrevolution.com/marginalrevolution/2023/11/what-do-we-know-about-non-profit-boards.html) that the literature on nonprofit governance is pretty negative, quoting [a 2014 paper by George Dent](https://scholarlycommons.law.case.edu/cgi/viewcontent.cgi?article=2096&context=faculty_publications):

> A remarkable consensus of experts on NPOs agrees that their governance is generally abysmal, considerably worse than that of for-profit corporations. NPO directors are mostly ill-informed, quarrelsome, clueless about their proper role, and dominated by the CEO-as proponents of shareholder primacy would predict.

"Dominated by the CEO" was apparently not true of OpenAI, but you gotta give them "quarrelsome."

Third, I really do have to quote last week's incredible [Wall Street Journal report](https://www.wsj.com/tech/ai/altman-firing-openai-520a3a8c) about the board's non-explanation of what Altman did to get himself fired:

> On the call, the leadership team pressed the board over the course of about 40 minutes for specific examples of Altman's lack of candor, the people said. The board refused, citing legal reasons, the people said. …
>
> The board agreed to discuss the matter with their counsel. After a few hours, they returned, still unwilling to provide specifics. They said that Altman wasn't candid, and often got his way. The board said that Altman had been so deft they couldn't even give a specific example, according to the people familiar with the executives. 

"Without realizing it, we were gradually overmatched by a superior intelligence, until he ended up controlling us in ways that are too subtle for us to even explain," thought the AI-nervous board of OpenAI. I love them. Their fears about rogue AI are [such obvious metaphors](https://www.bloomberg.com/opinion/articles/2023-11-20/who-controls-openai) for their mundane real-life problems. 

Fourth, last week [I asked](https://www.bloomberg.com/opinion/articles/2023-11-21/openai-is-a-strange-nonprofit) some questions like "did Microsoft agree to any sort of non-compete or non-solicit," and "does Altman have any sort of non-solicit?" I was careful not to ask "did OpenAI's employees sign non-competes," because I am aware (not legal advice!) that employee non-competes [don't work in California](https://calemploymentlawupdate.proskauer.com/2023/09/california-expands-prohibition-against-non-competes/). But a lot of readers emailed me to point that out anyway, and also pointed out that non-solicitation clauses are also [generally](https://ogletree.com/insights-resources/blog-posts/california-nonsolicitation-clause-held-enforceable-under-narrow-exception-for-sale-of-a-business/) [not enforced](https://kroghdecker.com/are-non-solicitation-agreements-enforceable-in-california#:~:text=Non%2Dsolicitation%20agreements%20are%20often,in%20violation%20of%20public%20policy.) in California. So, there, that's why.

Finally, it is a [long-running schtick](https://www.theverge.com/2022/10/28/23427137/elon-musk-twitter-matt-levine-money-stuff) of this column that whenever I take a day off, Elon Musk does something crazy. I took much of last week off for Thanksgiving. "I guess by Monday Elon Musk is going to own OpenAI and Binance," I [threaded](https://www.threads.net/@itismattlevine/post/Cz6xCKbu11p). But I wasn't really worried until OpenAI's new board [was announced](https://twitter.com/OpenAI/status/1727206187077370115). The chairman is [Bret Taylor](https://www.bloomberg.com/news/features/2022-09-14/who-is-twitter-chairman-bret-taylor-elon-musk-s-opposite), who was also the chairman of the board of Twitter Inc. when Musk bought it. I don't really think that Musk is going to buy OpenAI, but I am going to take some time off for the holidays in December so who knows.
