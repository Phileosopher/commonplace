
#### OpenAI - Matt Levine

Here is a partial list of things that Elon Musk has thought are the most important things in the world:

1. "[Solving the environment](https://www.cnbc.com/2018/11/05/elon-musk-teslas-work-is-important-to-the-future-of-the-world.html)," by building electric cars at Tesla.
2. Making humanity a "[multi-planet species](https://www.cnbc.com/2021/04/23/elon-musk-aiming-for-mars-so-humanity-is-not-a-single-planet-species.html)," by building spaceships at SpaceX.
3. Buying Twitter to prevent the "[corrosive effect on civilization](https://www.sfgate.com/local/article/elon-musk-claim-for-buying-twitter-sf-mind-virus-18462172.php)" of San Francisco's "mind virus."

I want to make a few points about this list. First: It's a fine list? Stopping climate change, colonizing space, and changing public discourse are all reasonable things to prioritize. There are tech founders who are like "I wanted to solve the problem that sometimes when I order food delivery, it arrives cold"; Elon Musk is not a founder like that.

Second: He has made a lot of progress on these problems. Tesla revolutionized electric cars; SpaceX revolutionized space; I personally do not care for the effect that Musk has had on the conversation at Twitter (now X), but he sure has had an effect, and I assume _he's_ happy with it. As a founder of companies intended to solve big problems, Elon Musk has been quite effective.

This is obvious stuff. "Elon Musk tackles big problems and is unusually good at solving them" is just conventional wisdom, which is why there are glowing biographies written about him and some days he's the richest person in the world. The main way to get really rich is by solving big problems successfully.

And that's the third point that I want to make about this list: When Elon Musk has looked around and identified a big problem and set about trying to solve it, he has done so by founding (or acquiring) a for-profit company that he owns and controls. This is not the only way to (try to) solve big problems. Bill Gates, for instance, got very rich by selling software and then decided to improve the world by donating a lot of money [to charitable works](https://www.gatesfoundation.org/our-work). Or various billionaires try to improve the world by supporting politicians who they think will do good things. Musk has [dabbled](https://www.nytimes.com/2024/03/05/us/politics/trump-elon-musk.html) in these approaches, but mostly they are not his preference. "[Most philanthropy was bulls-](https://www.cnn.com/2023/09/11/tech/elon-musk-bill-gates-isaacson-book/index.html#:~:text=Musk%20told%20Isaacson%20he%20felt,a%20short%20bet%20against%20Tesla.),' Musk told Gates" once, arguing that Tesla did more good for the world than most charities.

And this too is a pretty common view. It is not the only view - a lot of people think that philanthropy is good! - but in Silicon Valley tech circles it is [fairly conventional](https://www.motherjones.com/politics/2023/12/effective-accelerationism/) to [think that](https://www.axios.com/2023/10/21/philanthropy-selfish-billionaires) startups are a better way to improve the world than charity, that startups can be more ambitious, more focused on results, have a better alignment of interests and more motivated employees, and can raise and deploy a lot more money than charities. "Technological innovation in a market system is inherently philanthropic," [wrote Marc Andreessen last year](https://a16z.com/the-techno-optimist-manifesto/), in a "Techno-Optimist Manifesto" laying out this view.

Now, I don't think that Musk thinks that _all_ profit-seeking companies, or _all_ tech startups, are good; he criticizes lots of them, and had to go and buy Twitter because its previous management upset him. I just think that he thinks the best way to improve the world is generally through a for-profit company _that he runs_. And even _this_ view - "the highest form of philanthropy is a for-profit company run specifically by Elon Musk" - is pretty widespread. Larry Page [has mused about](https://nymag.com/intelligencer/2014/03/larry-pages-charity-problem.html) leaving his fortune to Musk, because Musk's for-profit businesses are more philanthropic than any philanthropies he can think of. 

Last week [Musk sued OpenAI](https://www.bloomberg.com/opinion/articles/2024-03-01/openai-isn-t-open-enough-for-elon), arguing that it was founded as a nonprofit organization to build artificial intelligence for the benefit of humanity, that he was a big donor to that nonprofit, and that it has turned into a for-profit company in violation of a supposed agreement not to. What I find strangest about all this is that OpenAI was a nonprofit to begin with: Its founders, people like Musk and Sam Altman, are generally leading proponents and examples of the idea that the best way to do good in the world is with a for-profit tech startup.

At some level I can understand why artificial intelligence is different from electric cars or rockets or [social networking](https://en.wikipedia.org/wiki/Loopt): Powerful artificial intelligence could potentially put humans out of work, enslave us, kill us, etc.; Altman [has said](https://www.wsj.com/tech/ai/elon-musk-sam-altman-openai-lawsuit-8e6f1897) that AI is "probably the greatest threat to the continued existence of humanity," terrific. Building AI that enriches its owners but immiserates everyone else would be bad. Still, all of the advantages of startups kind of remain true about AI. People might be more motivated to build AI if it will enrich them than if it won't. It was always an odd fit for Altman and Musk to start a noprofit together, an awkward choice to jam tech startup ideas and methods into a nonprofit box. 

Anyway [here's this](https://www.bloomberg.com/news/articles/2024-03-06/openai-responds-to-musk-lawsuit-sad-it-s-come-to-this):

> OpenAI fired back at a lawsuit filed against it by Elon Musk in a blog post Tuesday, using the billionaire's own emails to show he backed the company's plans to become a for-profit business and that he insisted it raise "billions" of dollars to be relevant compared with Google.

Here is [OpenAI's blog post](https://openai.com/blog/openai-elon-musk), which explains that OpenAI was founded as a nonprofit but eventually decided it needed more money than it could get from donors:

> We spent a lot of time trying to envision a plausible path to AGI. In early 2017, we came to the realization that building AGI will require vast quantities of compute. We began calculating how much compute an AGI might plausibly require. We all understood we were going to need a lot more capital to succeed at our mission-billions of dollars per year, which was far more than any of us, especially Elon, thought we'd be able to raise as the non-profit.

Yes, right, it turns out that it is easier to motivate people to give you computing power if you pay them for it, it is easier to motivate researchers to develop artificial intelligence if you [give them stock options](https://www.levels.fyi/blog/openai-compensation.html), and it is easier to get people to give you money if you [offer them a share](https://www.cnbc.com/2023/04/08/microsofts-complex-bet-on-openai-brings-potential-and-uncertainty.html) of your financial returns. (OpenAI has raised [roughly 100 times](https://www.bloomberg.com/opinion/articles/2024-03-01/openai-isn-t-open-enough-for-elon) as much money from investors as it ever did from donors.) If you want to build a car company or a rocket company or a social network, this is also true, so it seems intuitive to apply the same reasoning to AI.

Elon Musk knows this and, apparently, agreed that OpenAI should pivot to profit. But he took his usual view, that the best way to do good for the world was through a for-profit company _that he controlled_:

> In late 2017, we and Elon decided the next step for the mission was to create a for-profit entity. Elon wanted majority equity, initial board control, and to be CEO. In the middle of these discussions, he withheld funding. Reid Hoffman bridged the gap to cover salaries and operations.
> 
> We couldn't agree to terms on a for-profit with Elon because we felt it was against the mission for any individual to have absolute control over OpenAI. He then suggested instead merging OpenAI into Tesla. In early February 2018, Elon forwarded us an email suggesting that OpenAI should "attach to Tesla as its cash cow", commenting that it was "exactly rightâ€¦ Tesla is the only path that could even hope to hold a candle to Google. Even then, the probability of being a counterweight to Google is small. It just isn't zero".
> 
> Elon soon chose to leave OpenAI, saying that our probability of success was 0, and that he planned to build an AGI competitor within Tesla. When he left in late February 2018, he told our team he was supportive of us finding our own path to raising billions of dollars.

And now Elon Musk in fact [does have a for-profit artificial intelligence startup](https://www.wsj.com/tech/ai/elon-musks-x-leans-on-his-ai-startup-9038380d) that he controls and that competes with OpenAI. The Wall Street Journal [reports](https://www.wsj.com/tech/ai/elon-musk-sam-altman-openai-lawsuit-8e6f1897):

> After Musk filed his lawsuit, Altman wrote a memo to his staff: "The implication that benefiting humanity is somehow at odds with building a business is confusing," he said. "I miss the old Elon." 

No, see, he still thinks that building a business is the best way to benefit humanity, which is why he's doing it. But the old Elon also liked to make outlandish claims in court; you just can't take this stuff too seriously.
