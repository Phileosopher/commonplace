
bad graphs
1 check the y axis to see if it goes down to 0
  - it looks like a MUCH bigger difference if not
2 check that labels exist
  - without labels, it could mean anything
3 the bar size is discrepant
  - it needs to be legitimately proportional

## Statistics uses

Most [reality](reality.md) yields [statistical results](math-stat.md), so statistics has a vast range of applications. It can track how far someone can throw a ball, a rocket's likely trajectory, radioactive chemicals' half-life, and [social trends](trends.md). It can also often show how we change [habits](habits.md), [behave in groups](groups-member.md), and [make decisions](people-decisions.md).

Normally, we interpret [certainty](understanding-certainty.md) in our minds through convictions grounded in [experiences](understanding.md). Statistical systems, however, create an anomaly to that mode of reasoning:

1. Gathering statistics requires heaping up [stories](stories-why.md), but only for specific and measurable elements of those many, many stories, without any consideration of other things that aren't being measured.
2. All [analysis](logic.md) derived from the results can't naturally regard the qualitative experiences that were trimmed during collection.
3. Since we all need stories to [understand](understanding.md) reality, most statisticians easily interpret cause-and-effect through correlation.

Statistics are tracking reality, and reality is [uncertain](understanding-certainty.md), so all statistics are always a little uncertain. They're alarmingly accurate (when measured correctly) at determining correlation, but only in a broad sense.

Statistics, however, can *only* demonstrate correlation. Any causation only comes through how the information is [interpreted](stories-why.md):

- People in the 1980s who ate hot breakfasts more often than cold were dramatically more likely to have Alzheimer's Disease. We [tend](habits.md) to eat what we ate when we were kids, and cold cereal took off in [popularity](trends.md) in the 1950s.
- Crime statistics *always* go up when cities expand their police forces. Technically, crime statistics are only measuring *caught* crimes.
- The [culture](people-culture.md) of most of the world aligns with anthropology studies of the West, representative by data. Most anthropology data is gathered near Western universities.
- People who saw the 1984 Ghostbusters movie are more likely to die than people who saw the 2021 Ghostbusters movie. This is simply because of age-related facts.

APPLICATION: A statistical report is a statement of curated observations and is as trustworthy as the [group](groups-small.md) it came from. There's lots of [money and power](power.md) if someone can [prove](influence.md) they're not biased (which isn't [possible](mind-bias.md)), so the people who create statistics often [have something to lose](power-types.md) by stating that they're not precisely accurate.

When we hear a statistical result, we're incapable of *not* inserting our [explanation](logic.md) on the [causes or effects](stories-why.md) of the information. Our only hope to gain full [understanding](understanding.md) lies in forced [uncertainty](understanding-certainty.md), which requires directing our thoughts toward the specific [purpose](purpose.md) of suspending judgment, which requires tremendous effort to maintain.

Statistics don't fit our [intuition](mind-feelings.md) for a few core reasons:

- When there are different sample sizes from different groups (e.g., populations of various districts in a country), the less-populated groups are *guaranteed* to have more high/low extremes, simply from having fewer numbers.
- Observing statistical anomalies (e.g., very unusual height) creates more engaging [stories](stories-why.md) and spurs the [imagination](imagination.md), and it requires training to *not* [feel](mind-feelings.md) the outliers more than the norm.
- Possessing information on a chart doesn't explain anything directly. It indicates a connection, but that connection has to [stay unknown](unknown.md) for us to be accurate, and [we *hate* not knowing](purpose.md).
- When we experience the [possibility](imagination.md) of a [risk](safety.md), we only [feel](mind-feelings.md) comfortable when its chances become 0%. For that reason, we tend to obsess about the smaller risks (which can theoretically be eliminated) at the opportunity cost of managing the larger ones.
- Over time, statistical things [trend](trends.md) back to normal from extremes (e.g., high-performing athletes, extremely depressed people). Without measuring what normally happens, we can imagine that a statistical change was caused *by* a measured element included in it.

APPLICATION: We can never expect something to go *precisely* how we envision it because we always gain 1 sample of a statistical range at any given time. All we can do is [change our statistical likelihoods](success-2_attitude.md) whenever possible.

Very frequently, statistics [hide lies](people-image-distortion.md) by making the statistician appear more credible. The value of the statistical [analysis](logic.md) comes from the [value](creations.md) of the raw data, which comes from the [quality](values-quality.md) of the data collection.

APPLICATION: Claiming statistical analysis is immaculate requires faith in a [community's](groups-member.md) collective [understanding](understanding.md). Nothing is all/nothing, but statistics provide the opportunity to make a clear [story](stories-why.md) of reality, even if it's not precise. However, most [younger people](maturity.md) can be [influenced](influence.md) to [believe](understanding-certainty.md) statistics more than its truth.

---

# Statistics

Statistics is a relatively simple concept:

1. Find many similar things to measure (e.g., a population of people).
2. There's usually a *ton* of those things, so figure out how many of that thing to measure to give it [scientific rigor](science.md) without wasting too much time or money on it.
3. Pile up that information until it shows a bell curve across a numbered range.
4. Calculate the center of that bell curve, then determine where most of those things sit from that center. Typically, over half of everything will fit within 1 standard deviation, and about 95% will fit inside two of them.

Linearity vs nonlinearity is one of the central distinctions in mathematics.
Nonlinear thinking means which way you should go depends on where you already are.
The relation between eating and health isn't linear, but curved, with bad outcomes on both ends.

The Laffer curve:
The horizontal axis here is level of taxation, and the vertical axis represents the amount of revenue the government takes in from taxpayers.
On the left edge of the graph, the tax rate is 0%.

Linear reasoning is everywhere. You're doing it every time you say that if something is good to have, having more of it is even better.

Statistics are essential for reasoning about a huge variety of problems.
- but ONLY if that person has legitimate experience in that domain or something relatively similar.

statistical analysis is the WORST thing because it works against how our minds and bias operate
- a likely thing according to our minds isn't always statistically likely because we'll favor that odd experience and forget the rest of the time
- an unlikely thing according to our minds is statistically random, and we were just lucky/unlucky

QUIZ:
A test of a disease presents a rate of 5% false positives.
The disease strikes 1/1000 of the population.
People are tested at random, regardless of whether they are suspected of having the disease.
A patient's test is positive.
What is the probability of the patient having the disease?

Most doctors say 95%! True answer is 1/50. (2%).
The positive reading just made it 20 times more likely the patient has it. Now 1/1000 chance is increased to 1/50 chance.

Like actors into stardom, people patronize whatother people like to do. Forcing rational dynamics on the process would be impossible. This is called a "path dependent outcome" and has thwarted many mathematical attempts at modeling behavior.

Detecting covariation (or correlation): you have to pay attention to all
four cells in order to be able to answer the simple question about
association.
Compute the ratio comparing the number of people who don't have the
disease but do have the symptom with the number of people who don't have
the disease and don't have the symptom. Since the two ratios are the
same, you know that the symptom is not associated with the disease.
Often a given correlation is so consistent with plausible ideas about
causation that we tacitly accept that the correlation establishes that
there is a causal relation.
Causal inferences are often irresistible. If I tell you that people who
eat more chocolate have more acne, it's hard to resist the assumption
that something about chocolate causes acne. (It doesn't, so far as is
known.)
Inquiry is fatal to certainty. - Will Durant, philosopher

There is a fairly plausible hypothesis called the "germ exposure theory"
that could account for the correlational and natural experiment
evidence. Now are you ready to get your baby dirty? Personally, I'm not
sure I would be. Natural experiments, correlational evidence, and
plausible theories are all well and good. But I would want to see a true
experiment of the double-blind, randomized control sort, with babies
assigned by the proverbial flip of a coin to an experimental
high-bacteria exposure condition versus a control, low-bacteria
condition. Both the experimenter and the participants (the mothers in
this case) should be ignorant of (blind to) the condition the babies
were assigned to. Ignorance resulting from this double-blind design
rules out the possibility that results could have been influenced by
either the experimenter's or the participant's knowing what condition
the participant was in.
- this never happens in real life because measuring that information is often [taboo]

Studies that rely on correlations to establish a scientific fact can be
hopelessly misleading.

Does classroom size affect learning? Are multivitamins good for your
health? Is there employer prejudice against the long-term unemployed -
simply because they've been out of a job for a long time?
All the questions in this chapter ask whether some independent or
predictor variable - an input or a presumed cause - affects some
dependent or outcome variable - an output or an effect.

The smaller the sample size - the greater the variation.
The law of averages is not very well named, because laws should be true, and this one is false.
Coins have no memory. So the next coin you flip has a 50-50 chance of coming up heads, the same as any other.
The way the overall proportion settles down to 50% isn't that fate favors tails to compensate for the heads that have already landed; it's that those first ten flips become less and less important the more flips we make.

Don't talk about percentages of numbers when the numbers might be negative.

The more chances you give yourself to be surprised, the higher your threshold for surprise had better be.

The null hypothesis, in executive bullet-point form:
Run an experiment.
Suppose the null hypothesis is true, and let p be the probability (under that hypothesis) of getting results as extreme as those observed.
The number p is called the p-value.
If it is very small, rejoice; you get to say your results are statistically significant.
If it is large, concede that the null hypothesis has not been ruled out.

The lexical double-booking (double meaning) of the word "significance" has consequences.
Twice a tiny number is a tiny number.
Both numbers are more or less zero.
"Statistically noticeable" or "statistically detectable" would be a better term than "statistically significant"
That would be truer to the meaning of the method, which merely counsels us about the existence of an effect but is silent about its size or importance.
But it's too late for that. We have the language we have.

Statistical study that's not refined enough to detect a phenomenon of the expected size is called underpowered - the equivalent of looking at the planets with binoculars.
Moons or no moons, you get the same result, so you might as well not have bothered.

Players who had just made a shot were more likely to take a more difficult shot on their next attempt.
The "hot hand" in basketball might "cancel itself out": players, believing themselves to be hot, get overconfident and take shots they shouldn't.

Suppose the hypothesis H is true.
It follows from H that a certain fact F cannot be the case.
But F is the case. Therefore, H is false.
Suppose the null hypothesis H is true.
It follows from H that a certain outcome O is very improbable (say, less than Fisher's 0.05 threshold).
But O was actually observed. Therefore, H is very improbable.

Impossible things never happen. But improbable things happen a lot.

Scientists, subject to the intense pressure to publish lest they perish, are not immune to temptations.
It takes a lot of mental strength to stuff years of work in the file drawer.
Scientists may "torture the data until it confesses."

The purpose of statistics isn't to tell us what to believe, but to tell us what to do.
Statistics is about making decisions, not answering questions.

The average value of a large collection of measurements is about the same as the average value of a small collection,
whereas the extreme value of a large collection is considerably more extreme than that of a small collection.
The average scientist in tiny Belgium will be comparable to the average scientist in the United States,
even though the best scientist in the United States will in general be better than Belgium's best.

Questions arise naturally when one transcends one's self, family, and friends.
How many?
How long ago?
How far away?
How fast?
What links this to that?
Which is more likely?

Our innate desire for meaning and pattern can lead us astray if we don't remind ourselves of the ubiquity of coincidence.

Regression to the mean is the natural behavior of any random quantity.
Behavior is most likely to improve after punishment and to deteriorate after reward.
The sequel to a great movie is usually not as good as the original.
The same can be said of the novel after the best-seller, the album that follows the gold record.
Simply another instance of regression to the mean.

Statistics is to probability as engineering is to physics - an applied science based on a more intellectually stimulating foundational discipline.

Capture-recapture method:
Assume we want to know how many fish are in a certain lake.
We capture one hundred of them, mark them, and then let them go.
After allowing them to disperse about the lake, we catch another hundred fish and see what fraction of them are marked.
If eight of the hundred we capture are marked, then a reasonable estimate of the fraction of marked fish in the whole lake is 8 percent.
Of course, care must be taken that the marked fish don't die as a result of the marking, that they're more or less uniformly distributed about the lake, that the marked ones aren't only the slower or more gullible among the fish, etc.

Central limit theorem states that the sum (or the average) of a large bunch of measurements follows a normal curve even if the individual measurements themselves do not.

Quite often, two quantities are correlated without either one being the cause of the other.
Changes in both quantities to be the result of a third factor.
Body lice were considered a cause of good health.
When people took sick, their temperatures rose and caused the body lice to seek more hospitable abodes.
The lice and good health both departed because of the fever.
The correlation between the quality of a state's day-care programs and the reported rate of child sex abuse in them is certainly not causal, but merely indicates that better supervision results in more diligent reporting of the incidents which do occur.

A technically correct yet misleading statistic is the fact that heart disease and cancer are the two leading killers of Americans. This is undoubtedly true, but according to the Centers for Disease Control, accidental deaths - in car accidents, poisonings, drownings, falls, fires, and gun mishaps - result in more lost years of potential life, since the average age of these victims is considerably lower than that of the victims of cancer and heart disease.

High-profile psychological studies were more likely not to replicate than to stand up.
The famous psychological results are famous not because they are the most rigorously demonstrated, but because they're interesting.

Regression toward the mean: in any series of random events an extraordinary event is most likely to be followed, due purely to chance, by a more ordinary one.

The law of small numbers.
