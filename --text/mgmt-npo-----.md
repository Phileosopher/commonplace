
#### Elon vs. OpenAI - Matt Levine

I [wrote yesterday](https://www.bloomberg.com/opinion/articles/2024-02-29/the-board-of-directors-is-in-charge) about reports that the US Securities and Exchange Commission might be looking into whether OpenAI or its founder and chief executive officer, Sam Altman, might have misled its investors. Late last year, OpenAI's board briefly [fired Altman](https://www.bloomberg.com/opinion/articles/2023-11-20/who-controls-openai) for not being "consistently candid," and then reversed course and fired itself instead. So there is some reason to believe that somebody wasn't candid about something.

I had my doubts that it would rise to the level of securities fraud, though. For one thing, OpenAI is a [nonprofit organization](https://openai.com/our-structure), and even its for-profit subsidiary, OpenAI Global LLC, which _has_ raised money from investors, isn't all _that_ for-profit. I wrote: 

> At the top of OpenAI's operating agreement, it warns investors: "It would be wise to view any investment in OpenAI Global, LLC in the spirit of a donation, with the understanding that it may be difficult to know what role money will play in a post-[artificial general intelligence] world." I still don't know what Altman was supposedly not candid about, but whatever it was, how material can it possibly have been to investors, given what they signed up for? "Ooh he said it cost $50 million to train this model but it was really $53 million" or whatever, come on, the investors were donating money, they're not sweating the details.

But that wasn't quite right, was it? Nonprofits _can_ defraud their donors. Generally that sort of fraud is not about _financial results_; it is about the nonprofit's mission, and whether it is using the donors' money to advance that mission. If I ask you to donate to save the whales, and you give me $100,000 earmarked to save the whales, and I spend it all on luxury vacations for myself, I probably will get in trouble. I suppose if Altman was not candid about OpenAI's mission, or its pursuit of that mission, that really could have been a kind of fraud on OpenAI's donors. I mean investors. It could have been donation/securities fraud on the donors/investors.

Here's [one of them](https://www.bloomberg.com/news/articles/2024-03-01/musk-sues-openai-altman-for-breaching-firm-s-founding-mission)!

> Elon Musk sued OpenAI and its Chief Executive Officer Sam Altman, alleging they violated the artificial intelligence startup's founding mission by putting profit ahead of benefiting humanity.
> 
> The 52-year-old billionaire, who was a co-founder of OpenAI but is no longer involved, said in a lawsuit filed late Thursday in San Francisco that the company's close relationship with Microsoft Corp. has undermined its original mission of creating open-source technology that wouldn't be subject to corporate priorities.
> 
> Musk, who is also CEO of Tesla Inc., has been among the most outspoken about the dangers of AI and artificial general intelligence, or AGI. The release of OpenAI's ChatGPT more than a year ago popularized advances in AI technology and raised concerns about the risks surrounding the race to develop AGI, where computers are as smart as an average human.
> 
> "To this day, OpenAI Inc.'s website continues to profess that its charter is to ensure that AGI 'benefits all of humanity,'" the lawsuit said. "In reality, however, OpenAI Inc. has been transformed into a closed-source de facto subsidiary of the largest technology company in the world: Microsoft."

Here is [Musk's complaint](https://assets.bwbx.io/documents/users/iqjWHBFdfxIU/rYCUmwA4Xxpw/v0). It is essentially a complaint for breach of contract: Musk argues that he founded OpenAI with Altman and Greg Brockman, that they had a deal about how OpenAI would operate, and that Altman and Brockman have now gone back on the deal. The contract said that OpenAI would be a nonprofit, that it would be run for the benefit of humanity, that it would build artificial general intelligence and give it away for free, and that it would build open-source software (thus the name) and explain to the public how its models operate. But now OpenAI is run for profit, for the benefit of Microsoft and its other investors rather than humanity. It has built artificial general intelligence and is hoarding it for its own enrichment rather than giving it away.

One problem with this claim is that the contract doesn't _quite_ exist. Musk's lawsuit says that OpenAI has breached "the Founding Agreement" of OpenAI, capitalized like that, as though he, Altman and Brockman sat down and signed a piece of paper with "Founding Agreement" at the top, setting out how OpenAI would operate. But they didn't. From the complaint:

> This Founding Agreement is memorialized in, among other places, OpenAI, Inc.'s founding Articles of Incorporation and in numerous written communications between Plaintiff and Defendants over a multi-year period. …

That is: There is no document titled "Founding Agreement"; despite being wealthy sophisticated repeat startup founders who know a lot of lawyers, the founders never sat down and signed a contract. Instead, the "Founding Agreement" has to be inferred from other documents. Musk cites two:

1. There's a June 2015 email from Altman to Musk, with five numbered bullet points setting out a plan for building AI. "The mission would be to create the first general AI and use it for individual empowerment - i.e., the distributed version of the future that seems the safest," the first bullet point begins. "I think ideally we'd start with a group of 7-10 people, and plan to expand it from there," says the second, and "we have a nice extra building in Mountain View they can have." The third bullet point proposes a five-person governance board including Musk and Altman, and "we'd have an ongoing conversation about what work should be open-sourced and what shouldn't." In the fourth bullet point, Altman asks Musk to "be involved somehow in addition to just governance"; maybe he could "come by and talk to them about progress once a month or whatever." Musk replied to the email "Agree on all."
2. There is the December 2015 certificate of incorporation of OpenAI Inc., the nonprofit corporation that ultimately controls OpenAI. "The specific purpose of this corporation is to provide funding for research, development and distribution of technology related to artificial intelligence," it says. "The resulting technology will benefit the public and the corporation will seek to open source technology for the public benefit when applicable. The corporation is not organized for the private gain of any person. … No part of the net income or assets of this corporation shall ever inure to the benefit of any director, officer or member thereof or to the benefit of any private person."

And Musk donated money to OpenAI, the nonprofit, over the years: In 2016 and 2017, he was the biggest donor to OpenAI, and "all told, Mr. Musk contributed more than $44 million to OpenAI, Inc. between 2016 and September 2020." He also did other stuff for OpenAI: He helped with recruitment, paid rent on its offices, "regularly visited," and "was present for important company milestones." He ultimately [left his role with OpenAI in 2018](https://www.semafor.com/article/03/24/2023/the-secret-history-of-elon-musk-sam-altman-and-openai).

You can sort of wave your hands at all this and say "Musk had a contract with OpenAI in which he agreed to donate money and in exchange OpenAI explicitly agreed to be an open-source nonprofit forever," but I don't think that's exactly right? The email from Altman was an initial proposal, not a detailed contract setting out the permanent terms of their deal; it promised not to open-source the software forever but only to "have an ongoing conversation about what work should be open-sourced and what shouldn't." Money was not mentioned.

And the certificate of incorporation was not a contract between Musk and OpenAI: He didn't sign the certificate, and he wasn't a shareholder, because there were no shares (it's a nonprofit). OpenAI's fiduciary duties are not to him, as a co-founder, but to humanity. The evidence of a _specific deal_ between Musk and OpenAI is pretty thin.

Still, I sympathize? OpenAI Inc., the top-level company that controls OpenAI's business, really is incorporated as a nonprofit. It really was formed to work for the benefit of humanity and not "for the private gain of any person." And it really did take donations from Musk and use them to build its team. But it eventually set up a for-profit subsidiary, OpenAI Global LLC, which has managed to raise money from investors at an $86 billion valuation, and those investors (and OpenAI's employees - though not Altman) expect some (capped) financial return on that investment. [OpenAI says](https://openai.com/our-structure) that "it became increasingly clear that donations alone would not scale with the cost of computational power and talent required to push core research forward, jeopardizing our mission": It had to raise money from investors, by promising them returns, to achieve its mission. (It raised something like $130.5 million in total donations; it has raised something like [$13 billion](https://www.bloomberg.com/news/articles/2024-01-09/microsoft-s-openai-ties-face-potential-eu-merger-investigation) in investment commitments from Microsoft.)

I am sure OpenAI had good lawyers when it set up this structure, and I assume that as a technical matter none of this violates the certificate of incorporation or the nonprofit mission: A portion of the profits of _OpenAI Global LLC_ can go to employees and venture capitalists and Microsoft, even though "no part of the net income or assets of" _OpenAI Inc._ can. Still that is rather technical, and Musk has a point here:

> In 2017, Mr. Brockman and others suggested transforming OpenAI, Inc. from a nonprofit to a for-profit corporation. After a series of communications over several weeks, Mr. Musk told Mr. Brockman, Dr. Sutskever, and Mr. Altman "[e]ither go do something on your own or continue with OpenAI as a nonprofit. I will no longer fund OpenAI until you have made a firm commitment to stay or I'm just being a fool who is essentially providing free funding to a startup. Discussions are over."

That was before OpenAI launched its for-profit subsidiary, though. When it did, Musk sort of grudgingly tolerated it:

> On March 11, 2019, OpenAI, Inc. announced that it would be creating a for-profit subsidiary: OpenAI, L.P. Prospective investors were notified of an "important warning" at the top of the summary term sheet that the for-profit entity "exists to advance OpenAI Inc.'s [the nonprofit's] mission of ensuring that safe artificial general intelligence is developed and benefits all of humanity. The General Partner's duty to this mission and the principles advanced in the OpenAI Inc. Charter take precedence over any obligation to generate a profit." Accordingly, investors were expressly advised that "[i]t would be wise to view any investment in OpenAI LP in the spirit of a donation."
> 
> Following the announcement, Mr. Musk reached out to Mr. Altman asking him to "be explicit that I have no financial interest in the for-profit arm of OpenAI." However, Mr. Musk continued to support OpenAI, Inc., the non-profit, donating an additional $3.48 million in 2019.

But at that point he _was_ just providing free funding to a startup, wasn't he?

So Musk argues that they had a deal, and that OpenAI breached it in three ways. First, it licenses GPT-4, its most powerful model so far, to Microsoft. OpenAI, in its public statements and its charter and its deal with Microsoft, has said that it will seek to build _artificial general intelligence_ for the benefit of humanity, but that it can license lesser forms of artificial intelligence to Microsoft. So the question is: Is GPT-4 artificial general intelligence? Musk says yes:

> GPT-4 is not just capable of reasoning. It is better at reasoning than average humans. It scored in the 90th percentile on the Uniform Bar Exam for lawyers. It scored in the 99th percentile on the GRE Verbal Assessment. It even scored a 77% on the Advanced Sommelier examination. … 
> 
> GPT-4 is an AGI algorithm, and hence expressly outside the scope of Microsoft's September 2020 exclusive license with OpenAI. …
> 
> Under its new Board, it is not just developing but is actually refining an AGI to maximize profits for Microsoft, rather than for the benefit of humanity. 

Seems like a stretch, though Musk quotes "Microsoft's own researchers" saying that GPT-4 "could reasonably be viewed as an early (yet still incomplete version of an artificial general intelligence (AGI) system."

Second, GPT-4 is not open-source:

> GPT-4's internal design was kept and remains a complete secret except to OpenAI-and, on information and belief, Microsoft. There are no scientific publications describing the design of GPT-4. Instead, there are just press releases bragging about performance. On information and belief, this secrecy is primarily driven by commercial considerations, not safety. Although developed by OpenAI using contributions from Plaintiff and others that were intended to benefit the public, GPT-4 is now a _de facto_ Microsoft proprietary algorithm, which it has integrated into its Office software suite.

Again, there doesn't seem to be any actual agreement between OpenAI and Musk (or anyone else) promising to make everything open-source, but, sure, it's annoying that they built a model partly using his money and now won't let him see it.

Third, Musk objects to OpenAI "permitting Microsoft, a publicly traded for-profit corporation, to occupy a seat on OpenAI, Inc.'s Board of Directors and exert undue influence and control over OpenAI's non-profit activities." Microsoft is [just an observer](https://www.bloomberg.com/news/articles/2024-01-05/microsoft-picks-dee-templeton-as-openai-board-observer) on the board, not a voting member, but, right, its interests in OpenAI are probably not particularly _charitable_.

And Musk is asking the court, not for his donations back, but for an order making OpenAI do what it supposedly promised to do: Open up GPT-4's source code, make it freely available to the public, end Microsoft's exclusive license and board rights, and generally stop OpenAI's for-profit work.

Obviously one should be pretty cynical here. _Musk runs a for-profit artificial intelligence company_, xAI, which competes with OpenAI and has [raised money](https://www.bloomberg.com/news/articles/2024-01-20/musk-s-xai-secures-500-million-toward-1-billion-funding-goal) by [citing OpenAI's commercial success](https://www.bloomberg.com/news/articles/2024-02-05/xai-potential-investors-focus-on-muskonomy-openai-success). Blowing up that competitor's commercial prospects, as this lawsuit is trying to do, could help xAI. He also runs other companies - Tesla Inc., Twitter/X - that make use of AI. I suppose Musk's companies would benefit from reading OpenAI's source code and "scientific publications describing the design of GPT-4," so why not sue OpenAI and try to make that information public? Musk's protests about OpenAI's unseemly pursuit of AI profit for investors do look a little insincere, since he's doing the same thing.

But he does have kind of a reasonable gripe? OpenAI was founded as a nonprofit, raised a bunch of money from him as a donor to a nonprofit, and is now somehow an enormously valuable tech startup owned by people who are not him. After OpenAI fired Altman last November, but before it brought him back, it looked as if OpenAI's _for-profit investors_ - Microsoft, but also some venture capitalists, and the employees who owned quasi-equity - had lost a bunch of value. I [wrote at the time](https://www.bloomberg.com/opinion/articles/2023-11-21/openai-is-a-strange-nonprofit): 

> I feel like the lesson here is … "don't invest in nonprofits at an $86 billion valuation." Which I think has never come up before? Like as far as I can tell no one in human history has ever purchased shares in a nonprofit at an $86 billion valuation? Because purchasing shares in a nonprofit, at any valuation, is not a coherent thing to do? But then OpenAI made it happen, for the first time, and probably also the last.

But it turns out the investors were fine, and the correct lesson might be the opposite one: Don't _donate money_ to a nonprofit that is selling shares at an $86 billion valuation! You might be skeptical about putting an $86 billion valuation on a nonprofit, but probably you should be even more skeptical that a business with an $86 billion valuation is a nonprofit.
