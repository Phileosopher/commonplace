
## llm - llama

[LLaMA now goes faster on CPUs | Hacker News](https://news.ycombinator.com/item?id=39890262)
[LLaMA Now Goes Faster on CPUs](https://justine.lol/matmul/)

[Meta AI releases Code Llama 70B | Hacker News](https://news.ycombinator.com/item?id=39178886)
[AI at Meta on X: "Today we're releasing Code Llama 70B: a new, more performant version of our LLM for code generation - available under the same license as previous Code Llama models. Download the models ‚û°Ô∏è https://t.co/fa7Su5XWDC ‚Ä¢ CodeLlama-70B ‚Ä¢ CodeLlama-70B-Python ‚Ä¢ CodeLlama-70B-Instruct https://t.co/iZc8fapYEZ" / X](https://twitter.com/AIatMeta/status/1752013879532782075)

[How Is LLaMa.cpp Possible? | Hacker News](https://news.ycombinator.com/item?id=37140013)
[How is LLaMa.cpp possible?](https://finbarr.ca/how-is-llama-cpp-possible/)

[Ollama now supports AMD graphics cards | Hacker News](https://news.ycombinator.com/item?id=39718558)
[Ollama now supports AMD graphics cards ¬∑ Ollama Blog](https://ollama.com/blog/amd-preview)

[Ollama is now available on Windows in preview | Hacker News](https://news.ycombinator.com/item?id=39409650)
[Windows preview ¬∑ Ollama Blog](https://ollama.com/blog/windows-preview)

[OpenAI compatibility | Hacker News](https://news.ycombinator.com/item?id=39307330)
[OpenAI compatibility ¬∑ Ollama Blog](https://ollama.com/blog/openai-compatibility)

[Facebook LLAMA is being openly distributed via torrents | Hacker News](https://news.ycombinator.com/item?id=35007978)
[Save bandwidth by using a torrent to distribute more efficiently by ChristopherKing42 ¬∑ Pull Request #73 ¬∑ meta-llama/llama](https://github.com/meta-llama/llama/pull/73/files)

[LLaMA: A foundational, 65B-parameter large language model | Hacker News](https://news.ycombinator.com/item?id=34925944)
[Introducing LLaMA: A foundational, 65-billion-parameter language model](https://ai.meta.com/blog/large-language-model-llama-meta-ai/)

[Using LLaMA with M1 Mac and Python 3.11 | Hacker News](https://news.ycombinator.com/item?id=35122689)
[l1x/dev | Using LLaMA with M1 Mac](https://web.archive.org/web/20230329103559/https://dev.l1x.be/posts/2023/12/08/using-llama-with-m1-mac/)

[Show HN: Finetune LLaMA-7B on commodity GPUs using your own text | Hacker News](https://news.ycombinator.com/item?id=35256769)
[lxe/simple-llm-finetuner: Simple UI for LLM Model Finetuning](https://github.com/lxe/simple-llm-finetuner)

[The LLama Effect: Leak Sparked a Series of Open Source Alternatives to ChatGPT | Hacker News](https://news.ycombinator.com/item?id=35504428)
[The LLama Effect: How an Accidental Leak Sparked a Series of Impressive Open Source Alternatives to ChatGPT](https://thesequence.substack.com/p/the-llama-effect-how-an-accidental)

[Falcon 40B LLM (which beats Llama) now Apache 2.0 | Hacker News](https://news.ycombinator.com/item?id=36145185)
[Thomas Wolf on X: "The license of the Falcon 40B model has just been changed to‚Ä¶ Apache-2 which means that this model is now free for any usage including commercial use (and same for the 7B) üéâ" / X](https://twitter.com/Thom_Wolf/status/1663986216771936263)

[Show HN: 80% faster, 50% less memory, 0% loss of accuracy Llama finetuning | Hacker News](https://news.ycombinator.com/item?id=38487199)
[unslothai/unsloth: 5X faster 60% less memory QLoRA finetuning](https://github.com/unslothai/unsloth)
[Unsloth AI | Finetune AI & LLMs faster](https://unsloth.ai/)

[Purple Llama: Towards open trust and safety in generative AI | Hacker News](https://news.ycombinator.com/item?id=38556771)
[Announcing Purple Llama: Towards open trust and safety in the new world of generative AI](https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/)

[Meta LLM Compiler: neural optimizer and disassembler | Hacker News](https://news.ycombinator.com/item?id=40819479)
[AI at Meta on X: "Today we‚Äôre announcing Meta LLM Compiler, a family of models built on Meta Code Llama with additional code optimization and compiler capabilities. These models can emulate the compiler, predict optimal passes for code size, and disassemble code. They can be fine-tuned for new https://t.co/GFDZDbZ1VF" / X](https://x.com/AIatMeta/status/1806361623831171318)

## llm - llama2

[GitHub - MIBlue119/awesome-llama2-resources: just collections about Llama2](https://github.com/MIBlue119/awesome-llama2-resources)

[Run Llama 2 uncensored locally | Hacker News](https://news.ycombinator.com/item?id=36973584)
[Run Llama 2 uncensored locally ¬∑ Ollama Blog](https://ollama.com/blog/run-llama2-uncensored-locally)

[Llama 2 | Hacker News](https://news.ycombinator.com/item?id=36774627)
[Llama](https://llama.meta.com/)

[Fast and Portable Llama2 Inference on the Heterogeneous Edge | Hacker News](https://news.ycombinator.com/item?id=38246668)
[Fast and Portable Llama2 Inference on the Heterogeneous Edge](https://www.secondstate.io/articles/fast-llm-inference/)

## llm - llama 3

[Meta Llama 3 | Hacker News](https://news.ycombinator.com/item?id=40077533)
[Meta Llama 3](https://llama.meta.com/llama3/)

[Llama 3 implemented in pure NumPy | Hacker News](https://news.ycombinator.com/item?id=40378499)
[Llama 3 implemented in pure NumPy ¬∑ The Missing Papers](https://docs.likejazz.com/llama3.np/)

## llm - llama vs gpt

[Llama 3-V: Matching GPT4-V with a 100x smaller model and 500 dollars | Hacker News](https://news.ycombinator.com/item?id=40505099)
[Llama 3-V: Matching GPT4-V with a 100x smaller model and 500 dollars | by Aksh Garg | May, 2024 | Medium](https://aksh-garg.medium.com/llama-3v-building-an-open-source-gpt-4v-competitor-in-under-500-7dd8f1f6c9ee)

[Fine-tune your own Llama 2 to replace GPT-3.5/4 | Hacker News](https://news.ycombinator.com/item?id=37484135)

[Beating GPT-4 on HumanEval with a fine-tuned CodeLlama-34B | Hacker News](https://news.ycombinator.com/item?id=37267597)
[Phind](https://www.phind.com/blog/code-llama-beats-gpt4)
[Show HN: Phind.com - Generative AI search engine for developers | Hacker News](https://news.ycombinator.com/item?id=34884338)
[Phind Model beats GPT-4 at coding, with GPT-3.5 speed and 16k context | Hacker News](https://news.ycombinator.com/item?id=38088538)
[Show HN: Web search using a ChatGPT-like model that can cite its sources | Hacker News](https://news.ycombinator.com/item?id=33910863)
[Show HN: GPT-4-powered web searches for developers | Hacker News](https://news.ycombinator.com/item?id=35543668)
[Phind](https://www.phind.com/search?home=true)
Phind Is An AI-powered Search Engine That Helps You Find The Best Images For Your Project, As Fast As Possible.
[Phind: AI Search Engine and Pair Programmer](https://www.phind.com/)
[Phind-70B: Closing the code quality gap with GPT-4 Turbo while running 4x faster | Hacker News](https://news.ycombinator.com/item?id=39471388)
[Phind](https://www.phind.com/blog/introducing-phind-70b)

## llm optimizing

[ChatGPT: Optimizing Language Models For Dialog](https://openai.com/blog/chatgpt)
OpenAI (2022)

[Fine tune a 70B language model at home | Hacker News](https://news.ycombinator.com/item?id=39635483)
[Answer.AI - You can now train a 70b language model at home](https://www.answer.ai/posts/2024-03-06-fsdp-qlora.html)

[Finetuning Large Language Models | Hacker News](https://news.ycombinator.com/item?id=35666201)
[Finetuning Large Language Models](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)

[Takeaways from hundreds of LLM finetuning experiments with LoRA | Hacker News](https://news.ycombinator.com/item?id=37870930)
[Finetuning LLMs with LoRA and QLoRA: Insights from Hundreds of Experiments - Lightning AI](https://lightning.ai/pages/community/lora-insights/)

[How to Finetune GPT-Like Large Language Models on a Custom Dataset | Hacker News](https://news.ycombinator.com/item?id=36068850)
[How To Finetune GPT Like Large Language Models on a Custom Dataset - Lightning AI](https://lightning.ai/blog/how-to-finetune-gpt-like-large-language-models-on-a-custom-dataset/)

[Making AMD GPUs competitive for LLM inference | Hacker News](https://news.ycombinator.com/item?id=37066522)
[MLC | Making AMD GPUs competitive for LLM inference](https://blog.mlc.ai/2023/08/09/Making-AMD-GPUs-competitive-for-LLM-inference)
[MLC Web LLM](https://mlc.ai/web-llm/)
A Web-based Language Learning Model That Provides A Platform For Users To Train And Fine-tune AI Models For Natural Language Processing Tasks.
[MLC-LLM: GPT/Llama on consumer-class GPUs and phones | Hacker News](https://news.ycombinator.com/item?id=35763483)
[mlc-ai/mlc-llm: Enable everyone to develop, optimize and deploy AI models natively on everyone's devices.](https://github.com/mlc-ai/mlc-llm)
[üëã Welcome to MLC LLM - mlc-llm 0.1.0 documentation](https://llm.mlc.ai/docs/)
Even more impressively, they followed up with support for several Large Language Models:
[WebLLM | Home](https://webllm.mlc.ai/)

## llm - parallel processing

[Consistency LLM: converting LLMs to parallel decoders accelerates inference 3.5x | Hacker News](https://news.ycombinator.com/item?id=40302201)
[Consistency Large Language Models: A Family of Efficient Parallel Decoders | Hao AI Lab @ UCSD](https://hao-ai-lab.github.io/blogs/cllm/)

## llm-powered agents

[GitHub - hyp1231/awesome-llm-powered-agent: Awesome things about LLM-powered agents. Papers / Repos / Blogs / ...](https://github.com/hyp1231/awesome-llm-powered-agent)

## llm - pytorch

[A common mistake when NumPy's RNG with PyTorch | Hacker News](https://news.ycombinator.com/item?id=26767441)
[Using PyTorch + NumPy? You're making a mistake. ¬∑ Tanel P√§rnamaa](https://tanelp.github.io/posts/a-bug-that-plagues-thousands-of-open-source-ml-projects/)

[PyTorch: Where we are headed and why it looks a lot like Julia (but not exactly) | Hacker News](https://news.ycombinator.com/item?id=29354474)
[Where we are headed and why it looks a lot like Julia (but not exactly like Julia) - compiler - PyTorch Dev Discussions](https://dev-discuss.pytorch.org/t/where-we-are-headed-and-why-it-looks-a-lot-like-julia-but-not-exactly-like-julia/276)

[PyTorch 2.0 | Hacker News](https://news.ycombinator.com/item?id=35174612)
[PyTorch 2.0: Our next generation release that is faster, more Pythonic and Dynamic as ever | PyTorch](https://pytorch.org/blog/pytorch-2.0-release/)

[Compromised PyTorch-nightly dependency chain between December 25th - December 30 | Hacker News](https://news.ycombinator.com/item?id=34202662)
[Compromised PyTorch-nightly dependency chain between December 25th and December 30th, 2022. | PyTorch](https://pytorch.org/blog/compromised-nightly-dependency/)

[Accelerated PyTorch Training on M1 Mac | Hacker News](https://news.ycombinator.com/item?id=31424048)
[Introducing Accelerated PyTorch Training on Mac | PyTorch](https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/)

## llm self-hosted

[GitHub - imaurer/awesome-decentralized-llm: Collection of LLM resources that can be used to build products you can "own" or to perform reproducible research.](https://github.com/imaurer/awesome-decentralized-llm)

## llm token prediction

[Better and Faster Large Language Models via Multi-Token Prediction | Hacker News](https://news.ycombinator.com/item?id=40220851)
[[2404.19737] Better & Faster Large Language Models via Multi-token Prediction](https://arxiv.org/abs/2404.19737)

## llm training - chatbot

[Punctuated Equilibrium](https://michellekhuang.com/training-an-ai-chatbot-on-my-childhood-journal-entries/)
Training An AI Chatbot On My Childhood Journal Entries

[Replacing my best friends with an LLM trained on 500k group chat messages | Hacker News](https://news.ycombinator.com/item?id=35540154)
[Replacing my best friends with an LLM trained on 500,000 group chat messages](https://www.izzy.co/blogs/robo-boys.html)

[Markov Chat Bot Disaster Story | Hacker News](https://news.ycombinator.com/item?id=32021269)
[Markov Chat Bot Disaster Story](https://gist.github.com/aconbere/1982a5eb17b77817017a3da50914732f)

[Multi-agent chatbot murder mystery | Hacker News](https://news.ycombinator.com/item?id=40921989)
[React App](https://ai-murder-mystery.onrender.com/)

[Papers on the UX of AI programming assistants - Austin Z. Henley](https://austinhenley.com/blog/uxaicoding.html)

## llm training

[Improving Language Model Behavior By Training On A Curated Dataset](https://openai.com/research/improving-language-model-behavior)
OpenAI (2021)

[Autogenerating a Book Series from Three Years of iMessages | Hacker News](https://news.ycombinator.com/item?id=39615715)
[Autogenerating a Book Series From Three Years of iMessages | Ben Kettle](https://benkettle.xyz/posts/message-book/)

[Databricks Releases 15K Record Training Corpus for Instruction Tuning LLMs | Hacker News](https://news.ycombinator.com/item?id=35541861)
[dolly/data at master ¬∑ databrickslabs/dolly](https://github.com/databrickslabs/dolly/tree/master/data)

[OpenAssistant Conversations - Democratizing Large Language Model Alignment [pdf] | Hacker News](https://news.ycombinator.com/item?id=35582417)
[OA_Paper_2023_04_15.pdf - Google Drive](https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view)

[Show HN: Identify car crash editorial anti-patterns using NLP | Hacker News](https://news.ycombinator.com/item?id=28840700)

[GitHub - theimpossibleastronaut/awesome-linguistics: A curated list of anything remotely related to linguistics](https://github.com/theimpossibleastronaut/awesome-linguistics)

[Text Is All You Need | Hacker News](https://news.ycombinator.com/item?id=34847912)
[Text is All You Need - by Venkatesh Rao - Ribbonfarm Studio](https://studio.ribbonfarm.com/p/text-is-all-you-need)

## llm - voice cloning

[Weird A.I. Yankovic: a cursed deep dive into the world of voice cloning | Hacker News](https://news.ycombinator.com/item?id=37739233)
[Weird A.I. Yankovic, a cursed deep dive into the world of voice cloning - Waxy.org](https://waxy.org/2023/10/weird-ai-yankovic-voice-cloning/)
